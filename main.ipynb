{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Config import Config\n",
    "from Dataset import Dataset\n",
    "from BertFeatures import GenerateBertFeatures\n",
    "from BertClasiffier import BERTClasiffier\n",
    "from BertOutputEmbeddings import getEmbeddings\n",
    "from LSTM import LSTM\n",
    "from LSTMInputGenerator import Generator\n",
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "\n",
    "#Define Config\n",
    "config = Config()\n",
    "\n",
    "#Get datasets\n",
    "data = Dataset(config)\n",
    "data.GetTrainTestData()\n",
    "\n",
    "#Convert text data to BERT features\n",
    "input = GenerateBertFeatures(data, config)\n",
    "input.GetFeatures(BERT_MODEL_HUB)\n",
    "\n",
    "#train fine-tuned BERT\n",
    "classifier = BERTClasiffier(data, config, input)\n",
    "classifier.train(BERT_MODEL_HUB)\n",
    "\n",
    "#evaluate accuracy of fine-tuned BERT on validation set\n",
    "eval_metrics = classifier.evaluate()\n",
    "print(eval_metrics)\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "#extract embeddings for training dataset\n",
    "df_trn = getEmbeddings(data.df_train, data.train_df, data.trainData, data.index_l, classifier)\n",
    "#extract embeddings for validation dataset\n",
    "df_val = getEmbeddings(data.df_test, data.test_df, data.trainData, data.val_index_l, classifier)\n",
    "\n",
    "#split validation set into validation set and test set for LSTM\n",
    "#validation set will be used while training LSTM to optimize model\n",
    "#test set will be used as unseen dataset for evaluating performance of LSTM\n",
    "df_val, df_test = train_test_split(df_val, test_size=config.testSizeLSTM, random_state=35)\n",
    "\n",
    "#train LSTM, evaluate performance and get predicted probabilities\n",
    "model = LSTM(config)\n",
    "model.buildModel()\n",
    "\n",
    "gen = Generator(config)\n",
    "\n",
    "model.train(gen.train_generator(df_trn), gen.val_generator(df_val))\n",
    "evaluation_metrics = model.evaluate(gen.test_generator(df_test), df_test)\n",
    "test_predictions = model.predict(gen.test_generator(df_test))\n",
    "\n",
    "#get max probability (and thus the most likely industry) for every report\n",
    "predictions = []\n",
    "prediction_prob = []\n",
    "for value in test_predictions:\n",
    "  value = list(value)\n",
    "  predictions.append(value.index(max(value)))\n",
    "  prediction_prob.append(value)\n",
    "\n",
    "#form final dataframe and decode the previously label encoded industry labels\n",
    "df_test[\"predictions\"] = predictions\n",
    "df_test[\"prediction_prob\"] = prediction_prob\n",
    "df_test[\"Actual Industry\"] = data.LE.inverse_transform(df_test[\"label\"])\n",
    "df_test[\"Predicted Industry\"] = data.LE.inverse_transform(df_test[\"predictions\"])\n",
    "\n",
    "print df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
