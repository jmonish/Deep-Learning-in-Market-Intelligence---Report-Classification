{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install bert package for tensorflow v1\n",
    "!pip install bert-tensorflow==1.0.1\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm.notebook import tqdm #adds progress bars to show loop status\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class Dataset():\n",
    "\n",
    "    \"\"\"This class defines functions for reading data from csv file, encoding industry labels, splitting report data into training and test set, \n",
    "    and splitting reports into chunks of smaller text\n",
    "    Order of execution from top to bottom -\n",
    "    GetTrainTestData -> ApplySplit -> TrainTestSplit -> LabelData -> ReadData -> GetTextSplit\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self._dataSource = config.dataSource\n",
    "        self._testSize = config.testSize     \n",
    "\n",
    "    def ReadData(self, filePath):\n",
    "\n",
    "        \"\"\"Read data from csv file. Drop rows where report data is not present\"\"\"\n",
    "\n",
    "        data = pd.read_csv(self._dataSource)\n",
    "        data.dropna(subset = [\"Data\"], inplace = True)\n",
    "        return data\n",
    "\n",
    "    def LabelData(self):\n",
    "\n",
    "        \"\"\"Encode industry labels using label encoding\"\"\"\n",
    "\n",
    "        self.LE = LabelEncoder()\n",
    "        trainData = self.ReadData(self._dataSource)\n",
    "        trainData['Industry'] = self.LE.fit_transform(trainData['Industry'])\n",
    "        return trainData\n",
    "\n",
    "    def GetTextSplit(self, text1):\n",
    "\n",
    "        \"\"\"Function for splitting \"\"\"\n",
    "\n",
    "        maxSeqLength = self.config.maxSeqLength\n",
    "        overlap = self.config.overlap\n",
    "\n",
    "        l_total = []\n",
    "        l_parcial = []\n",
    "        if len(text1.split())//maxSeqLength >0:\n",
    "            n = len(text1.split())//maxSeqLength\n",
    "        else: \n",
    "            n = 1\n",
    "        for w in range(n):\n",
    "            if w == 0:\n",
    "                l_parcial = text1.split()[:maxSeqLength]\n",
    "                l_total.append(\" \".join(l_parcial))\n",
    "            else:\n",
    "                l_parcial = text1.split()[w*(maxSeqLength - overlap):w*(maxSeqLength - overlap) + maxSeqLength]\n",
    "                l_total.append(\" \".join(l_parcial))\n",
    "        return l_total\n",
    "\n",
    "    def TrainTestSplit(self):\n",
    "\n",
    "        \"\"\"Split data into training and test datasets\"\"\"\n",
    "\n",
    "        self.trainData = self.LabelData()\n",
    "        df_train, df_test = train_test_split(self.trainData, test_size = self._testSize, random_state = 123)\n",
    "        return df_train, df_test\n",
    "\n",
    "    def ApplySplit(self):\n",
    "\n",
    "        \"\"\"Function to apply the text split to every report in training and test datasets. Output is a dataframe which has a new column\n",
    "        corresponding to the list of broken chunks of every report.\"\"\"\n",
    "\n",
    "        df_train, df_test = self.TrainTestSplit()\n",
    "        df_train['text_split'] = df_train[\"Data\"].apply(self.GetTextSplit)\n",
    "        df_test['text_split'] = df_test[\"Data\"].apply(self.GetTextSplit)\n",
    "        return df_train, df_test\n",
    "\n",
    "    def GetTrainTestData(self):\n",
    "\n",
    "        \"\"\"Function to break down the list of broken report chunks into separate rows and retrive corresponding industry label for every row\"\"\"\n",
    "\n",
    "        self.df_train, self.df_test = self.ApplySplit()\n",
    "\n",
    "        train_l = []\n",
    "        label_l = []\n",
    "        self.index_l = []\n",
    "        for idx,row in self.df_train.iterrows():\n",
    "            for l in row['text_split']:\n",
    "                train_l.append(l)\n",
    "                label_l.append(row['Industry'])\n",
    "                self.index_l.append(idx)\n",
    "\n",
    "        self.train_df = pd.DataFrame({\"text\":train_l, \"label\":label_l})\n",
    "\n",
    "        val_l = []\n",
    "        val_label_l = []\n",
    "        self.val_index_l = []\n",
    "        for idx,row in self.df_test.iterrows():\n",
    "            for l in row['text_split']:\n",
    "                val_l.append(l)\n",
    "                val_label_l.append(row['Industry'])\n",
    "                self.val_index_l.append(idx)\n",
    "\n",
    "        self.test_df = pd.DataFrame({\"text\":val_l, \"label\":val_label_l})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
