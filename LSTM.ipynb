{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install bert package for tensorflow v1\n",
    "!pip install bert-tensorflow==1.0.1\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "from datetime import datetime\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tqdm.notebook import tqdm #adds progress bars to show loop status\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class LSTM(object):\n",
    "\n",
    "    \"\"\"This class consists of LSTM model definition and functions for training, evaluting and getting predictions from LSTM model. \n",
    "    While train, evaluate and predict funtions can be called independently, a general order of execution from top to bottom is -\n",
    "    predict -> evaluate -> train -> buildModel(internally called by train function)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def buildModel(self):\n",
    "        text_input = layers.Input(shape=(None,768,), dtype='float32', name='text')\n",
    "        l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "        encoded_text = layers.LSTM(self.config.model.lstm_units,)(l_mask)\n",
    "        dropout = layers.Dropout(self.config.model.lstm_dropout)(encoded_text)\n",
    "        out_dense = layers.Dense(self.config.model.dense_units, activation=self.config.model.dense_activation)(dropout)\n",
    "        # And we add a softmax classifier on top\n",
    "        out = layers.Dense(len(self.config.labelList), activation=self.config.model.output_activation)(out_dense)\n",
    "        # At model instantiation, we specify the input and the output:\n",
    "        model = keras.Model(inputs = text_input, outputs = out)\n",
    "        model.compile(optimizer=self.config.model.optimizer,\n",
    "              loss=self.config.model.loss,\n",
    "              metrics=self.config.model.metrics)\n",
    "        return model\n",
    "\n",
    "    def train(self, train_generator, val_generator):\n",
    "        call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.98, patience=2, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)\n",
    "        self.model = self.buildModel()\n",
    "        self.model.fit_generator(train_generator, steps_per_epoch=self.config.training.batches_per_epoch_train, epochs=self.config.model.num_epochs,\n",
    "                    validation_data=val_generator, validation_steps=self.config.training.batches_per_epoch_val, callbacks =[call_reduce] )\n",
    "        \n",
    "    def evaluate(self, test_generator, df_test):\n",
    "        num_sequences_val = len(df_test['emb'].to_list())\n",
    "        batch_size = self.config.training.batch_size_test\n",
    "        batches_per_epoch = self.config.training.batches_per_epoch_test\n",
    "        assert batch_size * batches_per_epoch == num_sequences_val\n",
    "        num_features= 768\n",
    "\n",
    "        #returns a list with loss and accuracy values\n",
    "        return self.model.evaluate_generator(test_generator, steps= batches_per_epoch)\n",
    "\n",
    "    def predict(self, generator):\n",
    "        batches_per_epoch = self.config.training.batches_per_epoch_test\n",
    "\n",
    "        #returns predicted probabilities\n",
    "        return self.model.predict(generator, steps = batches_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
